//
//  AudioPlayer.m
//  PitchPerfect
//
//  Created by Sam Bender on 11/27/15.
//  Copyright Â© 2015 Sam Bender. All rights reserved.
//

#import "SBAudioPlayer.h"
#import "SBPlayableNote.h"
#import <math.h>

#define SAMPLE_RATE 44100

@interface SBAudioPlayer()

@property (nonatomic) BOOL playForDuration;
@property (nonatomic) BOOL isPlaying;
@property (nonatomic) BOOL tempBufferListAllocated;
@property (nonatomic) AudioBufferList *tempAudioBufferList;
// consists of SBPlayableNotes
@property (readwrite, nonatomic, retain) NSMutableArray *notes;
@property (nonatomic, retain) NSMutableArray *persistentDiscardNotes;

@end

@implementation SBAudioPlayer

#pragma mark - Initialization

- (id) init
{
    self = [super init];
    if (self)
    {
        self.notes = [[NSMutableArray alloc] init];
        self.persistentDiscardNotes = [[NSMutableArray alloc] init];
        self.gain = 0.9;
    }
    return self;
}

+ (SBAudioPlayer*) sharedInstance
{
    static dispatch_once_t pred;
    static id sharedInstance = nil;
    dispatch_once(&pred, ^{
        sharedInstance = [[self alloc] init];
    });
    return sharedInstance;
}

- (void) dealloc
{
    if (self.tempBufferListAllocated)
    {
        free(self.tempAudioBufferList);
    }
}

#pragma mark - Public

- (void) play:(SBNote*)note
{
    if (note == nil)
    {
        NSLog(@"Warning: play:(SBNote*)note, note was nil");
        return;
    }
    
    SBPlayableNote *playableNote = [[SBPlayableNote alloc] initWithFrequency:note.frequency];
    playableNote.instrumentType = note.instrumentType;
    playableNote.duration = note.duration;
    playableNote.loudness = note.loudness;
    [self playablePlay:playableNote];
}

- (void) playablePlay:(SBPlayableNote*)playableNote
{
    if (playableNote == nil)
    {
        NSLog(@"Warning: play:(SBPlayableNote*)note, note was nil");
        return;
    }
    
    playableNote.toneStart = [NSDate date];
    if (playableNote.instrumentType == InstrumentTypePiano)
    {
        [playableNote loadAudioFile];
    }
    
    NSLog(@"<AudioPlayer> Add note (%@) to notes", playableNote);
    [self.notes addObject:playableNote];
    
    if (self.isPlaying == NO)
    {
        [self startOutput];
    }
}

- (void) stop
{
    if (self.notes != nil)
    {
        [self.notes removeAllObjects];
    }
    else
    {
        NSLog(@"Called 'stop' on AudioPlayer when there was nothing playing.");
    }
    
    self.isPlaying = NO;
    
    [[EZOutput sharedOutput] stopPlayback];
}

#pragma mark - Private

- (void) startOutput
{
    self.isPlaying = YES;
    
    EZOutput *sharedOutput = [EZOutput sharedOutput];
    if ([sharedOutput isPlaying])
    {
        NSLog(@"Warning: called startOutput when audio was already playing");
        return;
    }
    
    SBPlayableNote *note = self.notes[0];
    if (note.instrumentType == InstrumentTypePiano)
    {
        [sharedOutput setInputFormat:note.audioFile.clientFormat];
    }
    [sharedOutput setDataSource:self];
    [sharedOutput startPlayback];
}

- (OSStatus)        output:(EZOutput *)output
 shouldFillAudioBufferList:(AudioBufferList *)audioBufferList
        withNumberOfFrames:(UInt32)frames
                 timestamp:(const AudioTimeStamp *)timestamp
{
    /**
     * The following code fills the audio buffer list with the notes in the note array.
     */
    Float32 *bufferLeft = audioBufferList->mBuffers[0].mData;
    Float32 *bufferRight = audioBufferList->mBuffers[1].mData;
    
    // we have to clear the audio bufferlist because if we read a file in and the number of frames
    // is less than the size of the audio bufferlist then those ending frames will be added to
    // resulting in values greater than 1.0 or less than -1.0
    vDSP_vclr(bufferLeft, 1, frames);
    vDSP_vclr(bufferRight, 1, frames);
    
    if (self.micBufferFull)
    {
//        for (int i = 0; i < frames; i++)
//        {
//            bufferLeft[i] = 1.5 * self.micBuffer[0][i];
//            bufferRight[i] = 1.5 * self.micBuffer[0][i];
//        }
        self.micBufferFull = NO;
    }
    
    for (int i = 0; i < self.notes.count; i++)
    {
        SBPlayableNote *note = self.notes[i];
        
        if (note.waitFrames != 0)
        {
            note.waitFrames--;
            continue;
        }
        
        if (note.instrumentType == InstrumentTypeSineWave)
        {
            for (int frame = 0; frame < frames; frame++)
            {
                if (note.durationInFramesLeft == 0)
                {
                    continue;
                }
                
                //
                // I bet casting to float fixes this problem. oh god.
                //
                Float32 value = (Float32)(sin(note.positionInSineWave) * note.loudness);
                
                // prevents the clicking sound at end of a note
                static const NSInteger fadeOutFrames = 300;
                static const NSInteger fadeInFrames = 500; // 500
                NSInteger framesUsed = note.durationInFrames - note.durationInFramesLeft; // 0 index
                if (note.durationInFramesLeft <= fadeOutFrames)
                {
                    ///////// frames left             ///  total frames
                    value *= (Float32)(note.durationInFramesLeft) / (Float32)(fadeOutFrames);
                }
                else if (framesUsed < fadeInFrames) // fade in
                {
                    value *= (Float32)(framesUsed) / (Float32)(fadeInFrames);
                }
                
                bufferLeft[frame] += value;
                bufferRight[frame] += value;
                note.positionInSineWave += note.thetaIncrement;
                note.durationInFramesLeft--;
            }
            
            if (note.durationInFramesLeft == 0)
            {
                [self.persistentDiscardNotes addObject:note];
            }
        }
        else if (note.instrumentType == InstrumentTypePiano)
        {
            UInt32 bufferSize; // amount of frames actually read
            BOOL eof; // end of file
            
            if (self.notes.count > 0)
            {
                BOOL interleaved = [EZAudioUtilities isInterleaved:note.audioFile.clientFormat];
                if (interleaved)
                {
                    NSLog(@"WARNING: audio file client format is interleaved");
                }
                
                // make sure we've allocated our temp bufferlist
                if (self.tempBufferListAllocated == NO)
                {
                    UInt32 bytesPerFrame = note.audioFile.clientFormat.mBytesPerFrame;
                    UInt32 channelsPerFrame = note.audioFile.clientFormat.mChannelsPerFrame;
                    
                    self.tempAudioBufferList = [self
                                                createAudioBufferListWithChannelsPerFrame:channelsPerFrame
                                                interleaved:interleaved
                                                bytesPerFrame:bytesPerFrame
                                                capacityFrames:frames];
                }
                
                // for some reason if we don't do this we get an error, something to do with mp3
                // maybe
                SInt64 diff = note.audioFile.totalFrames - note.audioFile.frameIndex;
                
                if (diff != 0)
                {
                    // clear temp buffer first
                    Float32 *tempBufferLeft = self.tempAudioBufferList->mBuffers[0].mData;
                    Float32 *tempBufferRight = self.tempAudioBufferList->mBuffers[1].mData;
                    vDSP_vclr(tempBufferLeft, 1, frames);
                    vDSP_vclr(tempBufferRight, 1, frames);
                    
                    //
                    // Read in to temporary buffer list
                    //
                    [note.audioFile readFrames:frames
                               audioBufferList:self.tempAudioBufferList
                                    bufferSize:&bufferSize
                                           eof:&eof];
                    
                    //
                    // Add to output buffer list
                    //
                    vDSP_vadd(bufferLeft, 1, tempBufferLeft, 1, bufferLeft, 1, frames);
                    vDSP_vadd(bufferRight, 1, tempBufferRight, 1, bufferRight, 1, frames);
                }
                else
                {
                    eof = YES;
                }
                
                // reset temporary bufferlist size
                // http://stackoverflow.com/a/23579336/337934
                AudioBuffer *buffer;
                for(int j = 0; j < self.tempAudioBufferList->mNumberBuffers; j++ )
                {
                    buffer = &( self.tempAudioBufferList->mBuffers[ j ] );
                    buffer->mDataByteSize = audioBufferList->mBuffers[0].mDataByteSize;
                }
            }
            else
            {
                // just one audio file, we can save some processing and read it straight to
                // the ouptut audio buffer list
                [note.audioFile readFrames:frames
                           audioBufferList:audioBufferList
                                bufferSize:&bufferSize
                                       eof:&eof];
            }
            
            
            // remove note if we are done
            if (eof)
            {
                [self.persistentDiscardNotes addObject:note];
            }
        }
    }
    
    [self.notes removeObjectsInArray:self.persistentDiscardNotes];
    [self.persistentDiscardNotes removeAllObjects];
    
    if (self.notes.count == 0)
    {
        [self stop];
    }
    
    // apply gain
    if (self.gain != 1.0)
    {
        vDSP_vsmul ( bufferLeft, 1, &_gain, bufferLeft, 1, frames);
        vDSP_vsmul ( bufferRight, 1, &_gain, bufferRight, 1, frames);
    }
    
    return noErr;
}

#pragma mark - Change pitch of audio files

- (double) percentCompressionFromFreq:(double)fromFreq toFreq:(double)toFreq
{
    return toFreq / fromFreq;
}

- (NSInteger) frameCountForCompression:(double)compression
                    andRequestedFrames:(NSInteger)requestedFrames
{
    return (NSInteger)(compression * (double)requestedFrames);
}

- (double) valueForFrame:(NSInteger)frameIndex withData:(Float32*)data dataLength:(NSInteger)dataLength requestedFrames:(NSInteger)requestedFrames
{
    double exactPos = ((double)frameIndex / (double)requestedFrames) * (double)dataLength;
    int left = floor(exactPos);
    int right = ceil(exactPos);
    double leftVal = data[left];
    double rightVal = data[right];
    double offset = exactPos - (double)left;
    double value = leftVal + offset * (rightVal - leftVal);
    return value;
}

#pragma mark - Misc

// http://stackoverflow.com/a/3796721/337934
- (AudioBufferList*) createAudioBufferListWithChannelsPerFrame:(UInt32)channelsPerFrame
                                                   interleaved:(BOOL)interleaved
                                                 bytesPerFrame:(UInt32)bytesPerFrame
                                                capacityFrames:(UInt32)capacityFrames
{
    if (self.tempBufferListAllocated == YES)
    {
        free(self.tempAudioBufferList);
    }
    else
    {
        self.tempBufferListAllocated = YES;
    }
    
    AudioBufferList *bufferList = NULL;
    
    UInt32 numBuffers = interleaved ? 1 : channelsPerFrame;
    UInt32 channelsPerBuffer = interleaved ? channelsPerFrame : 1;
    
    bufferList = calloc(1, offsetof(AudioBufferList, mBuffers) + (sizeof(AudioBuffer) * numBuffers));
    
    bufferList->mNumberBuffers = numBuffers;
    
    for(UInt32 bufferIndex = 0; bufferIndex < bufferList->mNumberBuffers; ++bufferIndex) {
        bufferList->mBuffers[bufferIndex].mData = calloc(capacityFrames, bytesPerFrame);
        bufferList->mBuffers[bufferIndex].mDataByteSize = capacityFrames * bytesPerFrame;
        bufferList->mBuffers[bufferIndex].mNumberChannels = channelsPerBuffer;
    }
    
    return bufferList;
}

@end
